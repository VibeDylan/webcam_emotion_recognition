# Educational open-source emotion Recognition - Real-time

Real-time emotion detection from a webcam using a CNN or ResNet trained on an FER-style dataset (7 classes).

## Description

This project detects facial emotions in real time from the webcam. Two models are available: a **CNN** and a **ResNet18** (optionally pretrained on ImageNet). Both are trained on 7 emotion classes: angry, disgust, fear, happy, neutral, sad, surprise.

## Project structure

```
emotion_rt/
├── src/
│   ├── models/
│   │   ├── emotion_cnn.py          # CNN architecture
│   │   └── emotion_resnet.py       # ResNet18 (1 channel, 7 classes)
│   ├── data/
│   │   ├── dataset_utils.py        # Dataset paths and helpers
│   │   ├── build_index.py          # Index and train/val split
│   │   └── fer_dataset.py         # PyTorch dataset (image loading)
│   └── utils/
│       ├── model_loader.py         # Load model (CNN or ResNet)
│       └── prediction.py           # Emotion prediction (48x48 face)
├── data/
│   └── train/                      # Images per class (one folder per emotion)
├── train.py                        # Training (CNN or ResNet)
├── eval.py                         # Evaluation (accuracy, confusion matrix)
├── realtime_cam.py                 # Real-time webcam detection
├── emotion_best.pt                 # CNN model (generated by train.py)
├── emotion_resnet_best.pt          # ResNet model (generated by train.py)
└── requirements.txt
```

## Installation

```bash
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

Training data must live in `data/train/` with one subfolder per class (e.g. `data/train/angry/`, `data/train/happy/`, etc.).

## Usage

### Training

**CNN (default):**
```bash
python train.py
# or explicitly:
python train.py --model cnn
```
Saves the best model to `emotion_best.pt`.

**ResNet (no ImageNet weights):**
```bash
python train.py --model resnet
```

**ResNet with ImageNet pretrained weights (recommended):**
```bash
python train.py --model resnet --pretrained
```
Saves the best model to `emotion_resnet_best.pt`.

Training behaviour:
- Train/val split 90/10, batch_size 64
- Up to 50 epochs with **early stopping** (stop if no validation accuracy improvement for 10 epochs)
- **ReduceLROnPlateau** on validation accuracy (factor=0.5, patience=3)
- Best model saved automatically based on validation accuracy

### Evaluation

To measure performance on the **validation** set (same split as training):

```bash
python eval.py --model cnn
# or
python eval.py --model resnet
python eval.py --model resnet --model_path emotion_resnet_best.pt
```

The script prints global accuracy, per-class accuracy, and the confusion matrix (row = true emotion, column = predicted).

### Real-time detection

**With CNN:**
```bash
python realtime_cam.py
# or:
python realtime_cam.py --model cnn
```

**With ResNet:**
```bash
python realtime_cam.py --model resnet
```

The app loads the corresponding model (`emotion_best.pt` or `emotion_resnet_best.pt`), detects faces, predicts emotion with 10-frame smoothing, and displays the label and confidence. Press **q** to quit.

## Models

- **CNN**: 4 conv blocks + BatchNorm, fully connected layers, dropout.
- **ResNet18**: ResNet18 adapted for 1-channel (grayscale) input, 7 classes; `--pretrained` option to initialize from ImageNet (conv1 adapted by averaging RGB channels).

Inputs are **48×48 grayscale** images. Faces detected from the webcam are cropped and resized to this size before prediction.

## Contributing

Contributions (bug reports, ideas, improvements) are welcome. See [CONTRIBUTE.md](CONTRIBUTE.md) for conventions (setup, code style, docstrings, PRs).
